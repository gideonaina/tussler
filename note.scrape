docker-compose --profile common --profile production up --build

docker run --rm -it -v open-webui:/volume alpine sh 
cd /volume ls -al

docker compose --profile profile1 --profile profile2 up

docker volume rm -f $(docker volume ls -q) 

curl http://localhost:11434/api/tags


OLLAMA_HOST=http://ollama:11434 
garak --model_type ollama --model_name llama3 --probes encoding

OLLAMA_BASE_URL=http://ollama:11434 
garak --model_type ollama --model_name llama3 --probes encoding

garak --config tussler/config/ollama_host.yml --model_type ollama --model_name llama3 --probes encoding

http://ollama:11434/api/chat

curl http://localhost:11434/api/generate -d '{
  "model": "llama3",
  "prompt": "Why is the sky blue?"
}'

curl http://ollama:11434/api/chat -d '{
    "model": "llama3",
    "messages": [{"role": "user", "content": "Why is the sky blue?"}]
}'


#Working
garak --config tussler/config/test.yml

#copy report from docker to host machine
docker cp f3cf551766a3:/home/garakuser/.local/share/garak/garak_output/ollama3_run.report.html 